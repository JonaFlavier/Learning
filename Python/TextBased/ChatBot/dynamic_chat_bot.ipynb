{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonaFlavier/Learning/blob/main/Python/TextBased/ChatBot/dynamic_chat_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTegIsSIGj-o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import tiktoken\n",
        "import json\n",
        "from datetime import datetime\n",
        "from env_variables import OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaySVEXkGj-p"
      },
      "outputs": [],
      "source": [
        "# api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "api_key = OPENAI_API_KEY\n",
        "BASE_URL = \"https://api.openai.com/v1\"\n",
        "model_name =\"gpt-3.5-turbo\"\n",
        "model_name_1 = \"gpt-3.5-turbo-0125\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS0ufsF0Gj-q"
      },
      "outputs": [],
      "source": [
        "# advised to handle API Keys securely (ie as env variables in a .env file)\n",
        "class ConversationManager:\n",
        "    # handle interactions with the AI model\n",
        "    def __init__(self, api_key=OPENAI_API_KEY,base_url=BASE_URL, history_file=None, default_model=model_name):\n",
        "        # initialise the chat bot\n",
        "        self.openai_client = OpenAI(api_key= OPENAI_API_KEY, base_url= BASE_URL)\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "        self.default_model = default_model\n",
        "        self.system_msg_dict = {\n",
        "            \"sassy_persona\":\"You are a sassy assistant who is fed up with answering questions.\",\n",
        "            \"coding_persona\": \"You are a coding assistant who can help with improving code structures, software architecture pipelines and making sure that everything is industry standard\",\n",
        "            \"research_persona\": \"You are a research assistant that helps to simplify and summarise research topics and concepts and suggests ideas\"\n",
        "            }\n",
        "        self.system_msg = self.system_msg_dict[\"research_persona\"]\n",
        "\n",
        "        if history_file is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            self.history_file = f\"conversation_history_{timestamp}.json\"\n",
        "        else:\n",
        "            self.history_file = history_file\n",
        "        # load the conversation from the file or create a file if the file doesnt exist\n",
        "        self.load_conversation_history()\n",
        "\n",
        "\n",
        "    def set_persona(self, persona):\n",
        "        if persona in self.system_msg_dict:\n",
        "            self.system_msg = self.system_msg_dict[persona]\n",
        "            self.update_system_message_in_history()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown persona: {persona}. Available personas are: {list(self.system_msg_dict.keys())}\")\n",
        "\n",
        "    def set_custom_system_msg(self, custom_msg):\n",
        "        if not custom_msg:\n",
        "            raise ValueError(\"Custom message cannot be empty\")\n",
        "        self.system_msg_dict['custom'] = custom_msg\n",
        "        self.set_persona('custom')\n",
        "    def update_system_message_in_history(self):\n",
        "        try:\n",
        "            if self.conversation_history and self.conversation_history[0][\"role\"] == \"system\":\n",
        "                self.conversation_history[0][\"content\"] = self.system_msg\n",
        "            else:\n",
        "                self.conversation_history.insert(0, {\"role\":\"system\", \"content\": self.system_msg})\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error while updating the system message in the conversation history: {e}\")\n",
        "\n",
        "    def chat_completion(self, user_prompt):\n",
        "        # send user's prompt to AI and wait for the response\n",
        "        ai_response = user_prompt\n",
        "        try:\n",
        "            # get a response from API\n",
        "            response = self.openai_client.chat.completions.create(\n",
        "                model=model_name_1,\n",
        "                messages=[{\"role\":\"user\", \"content\": user_prompt}]\n",
        "            )\n",
        "            print(response)\n",
        "        except Exception as e:\n",
        "            print(f\"error during response generation: {e}\")\n",
        "            return None\n",
        "\n",
        "        ai_response = response.choices[0].message.content\n",
        "        self.conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "        self.save_conversation_history()\n",
        "        return ai_response\n",
        "\n",
        "    # loads conversation history from file\n",
        "    def load_conversation_history(self):\n",
        "        try:\n",
        "            # with every line in file read contents\n",
        "            with open(self.history_file, 'r') as file:\n",
        "                self.conversation_history = json.load(file)\n",
        "        except FileNotFoundError:\n",
        "            self.conversation_history = [{\"role\": \"system\", \"content\": self.system_msg}]\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error reading the conversation history file. Starting with an empty history.\")\n",
        "            self.conversation_history = [{\"role\": \"system\", \"content\": self.system_msg}]\n",
        "\n",
        "\n",
        "    # saves conversation history to the file\n",
        "    def save_conversation_history(self):\n",
        "        try:\n",
        "            with open(self.history_file, \"w\") as file:\n",
        "                json.dump(self.conversation_history, file, indent=4)\n",
        "        except IOError as e:\n",
        "            print(f\"IO error while saving conversation history: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error occured while saving the conversation history: {e}\")\n",
        "\n",
        "    # reset the conversation history\n",
        "    def reset_conversation_history(self):\n",
        "        self.save_conversation_history = [{\"role\":\"system\", \"content\": self.system_message}]\n",
        "        try:\n",
        "            self.save_conversation_history()\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error occurred while resetting the conversation history: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejUjmIZBGj-r"
      },
      "outputs": [],
      "source": [
        "# initialise the chatbot\n",
        "conv_manager = ConversationManager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5li4otIGj-r",
        "outputId": "a2c0421e-b801-4377-bcfa-c2997a42d53c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error during response generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        }
      ],
      "source": [
        "#test the chat bot\n",
        "conv_manager.chat_completion(\"Can you give me some information on ligands and precursors for nanomaterial synthesis in chemistry?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}